# Transformaci√≥n y Limpieza de Datos en Pandas (sin imputaci√≥n)

Este documento presenta t√©cnicas **sin imputaci√≥n** para preparar y transformar datos usando pandas: detecci√≥n/eliminaci√≥n de nulos, normalizaci√≥n de datos semi‚Äëestructurados (strings, listas y fechas).

---

## 1. Manejo de valores faltantes (sin imputaci√≥n)

En esta ayudant√≠a **no haremos imputaci√≥n** de valores (nada de promedios/medianas). Solo detectaremos y eliminaremos casos problem√°ticos, o los **marcaremos** para procesarlos despu√©s.

### Dataframe Inicial

```python
import pandas as pd

df = pd.DataFrame({
    'id': [' 001','002','003','004','003 '],
    'nombre_completo': ['ana G√ìmez','  LUIS  p√©rez ','Sof√≠a  D√≠az', None,'sofia  D√çAZ'],
    'emails': ['ana@uc.cl; ana@gmail.com', 'l.perez@uc.cl', 'sdiaz@uc.cl;SOFIA@MAIL.COM', 'pedro@uc.cl', None],
    'fecha_atencion': ['12/03/2024','31-04-2024','2024-05-10','2024-06-15','10-05-24'],
    'monto': ['10000', '12.500', '4500', '15.750', 'USD 3,000']
    'fono': ['123456789', '9-8765-4321', '(+56) 9 1111 2222', '987654321', 'fono: 456789123']

})

df
```
|   | id   | nombre_completo    | emails                      | fecha_atencion | monto     | fono              |
|---|------|--------------------|-----------------------------|----------------|-----------|-------------------|
| 0 |  001 | ana G√ìmez          | ana@uc.cl; ana@gmail.com    | 12/03/2024     | 10000     | 123456789         |
| 1 | 002  |   LUIS  p√©rez      | l.perez@uc.cl               | 31-04-2024     | 12.500    | 9-8765-4321       |
| 2 | 003  | Sof√≠a  D√≠az        | sdiaz@uc.cl;SOFIA@MAIL.COM  | 2024-05-10     | 4500      | (+56) 9 1111 2222 |
| 3 | 004  | None               | pedro@uc.cl                 | 2024-06-15     | 15.750    | 987654321         |
| 4 | 003  | sofia  D√çAZ        | None                        | 10-05-24       | USD 3,000 | fono: 456789123   |


### Detecci√≥n
```python
df.info() # Vista general de tipos y nulos
df.isna().sum()  # Conteo de NaN por columna
df[df['col'].isna()] # Filas donde 'col' es NaN
```

### Eliminaci√≥n de duplicados

```python
# Eliminar filas duplicadas seg√∫n todas las columnas
df_sin_duplicados = df.drop_duplicates()

# Eliminar duplicados solo considerando la columna 'id'
df_sin_duplicados = df.drop_duplicates(subset=['id'])

# Ejemplo: eliminar duplicados considerando 'id' y 'nombre_completo'
df_sin_duplicados = df.drop_duplicates(subset=['id', 'nombre_completo'])
```


### Eliminaci√≥n de nulos
```python
df_limpio = df.dropna()                       # Elimina filas con al menos un NaN
df_limpio = df.dropna(subset=['colA','colB']) # Solo si A o B son NaN
df_limpio = df.dropna(how='all')              # Elimina filas completamente vac√≠as
```

```python
# Ejemplo: eliminar filas donde 'nombre_completo' es nulo
df = df.dropna(subset=['nombre_completo'])
```

### Resultado tras limpieza y eliminaci√≥n de nulos

|   | id   | nombre_completo | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------------------------|----------------|-----------|--------------|
| 0 | 001  | ana G√ìmez       | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 002  |   LUIS  p√©rez   | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 003  | Sof√≠a  D√≠az     | sdiaz@uc.cl;SOFIA@MAIL.COM | 2024-05-10     | 4500      | 911112222    |
| 4 | 003  | sofia  D√çAZ     | None                       | 10-05-24       | USD 3,000 | 456789123    |

Es necesario hacer `df.reset_index(drop=True, inplace=True)`

|   | id   | nombre_completo | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------------------------|----------------|-----------|--------------|
| 0 | 001  | ana G√ìmez       | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 002  |   LUIS  p√©rez   | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 003  | Sof√≠a  D√≠az     | sdiaz@uc.cl;SOFIA@MAIL.COM | 2024-05-10     | 4500      | 911112222    |
| 3 | 003  | sofia  D√çAZ     | None                       | 10-05-24       | USD 3,000 | 456789123    |

> Se elimin√≥ la fila con `nombre_completo` nulo (√≠ndice 3).

> üí° Sugerencia pr√°ctica: cuando elimines, **registra cu√°ntas filas** se van, para justificar tus decisiones en la I1/Tarea.

---

## 2. Normalizaci√≥n de datos semi‚Äëestructurados

Muchos datasets llegan con texto ‚Äúsucio‚Äù o comprimido en una sola columna. Usaremos el API de strings de pandas (`.str`) y algunas transformaciones.

### 2.0 `str`

La funci√≥n ``str`` en pandas se utiliza para realizar operaciones vectorizadas sobre datos de tipo cadena (strings) en una Serie o columna de un DataFrame. Esto significa que puedes aplicar m√©todos de manipulaci√≥n de cadenas de manera eficiente a todos los elementos de una columna sin necesidad de usar bucles expl√≠citos.

Por ejemplo, puedes usar ``str`` para convertir texto a min√∫sculas, eliminar espacios en blanco, buscar patrones, reemplazar texto, dividir cadenas, entre otras operaciones.

- La funci√≥n ``str`` solo funciona con datos de tipo cadena. Si la columna contiene valores nulos (NaN) o tipos diferentes, es posible que necesites manejar esos casos antes de usarla.
- Es una herramienta poderosa para limpiar y transformar datos textuales en proyectos de an√°lisis de datos.


### Ejemplo pr√°ctico de uso de `.str`

Sup√≥n que tienes una columna con nombres desordenados y quieres estandarizarlos:

```python
df = pd.DataFrame({'nombre': ['  ana G√ìmez', 'LUIS   P√âREZ', 'soF√≠a   d√≠Az  ']})

# Usando .str para limpiar espacios y normalizar may√∫sculas/min√∫sculas
df['nombre_limpio'] = (df['nombre']
                       .str.strip()                # Elimina espacios al inicio/final
                       .str.title()                # Convierte a Title Case
                       .str.replace(r'\s+', ' ', regex=True))  # Elimina espacios extra

print(df)
```

Resultado:

|      | nombre           | nombre_limpio   |
|------|------------------|-----------------|
| 0    |   ana G√ìmez      | Ana G√≥mez       |
| 1    | LUIS   P√âREZ     | Luis P√©rez      |
| 2    | soF√≠a   d√≠Az     | Sof√≠a D√≠az      |



### 2.1. Limpieza de strings

`strip()` elimina los espacios en blanco al inicio y al final de un string.  
Por ejemplo: `" hola ".strip()` devuelve `"hola"`.

Tambi√©n puedes usar:  
- `lstrip()` para quitar solo los espacios a la izquierda.  
- `rstrip()` para quitar solo los espacios a la derecha.
```python
# Estandarizar may√∫sculas/min√∫sculas y espacios

df['nombres'] = df['nombres'].str.strip().str.title() 
df['emails']  = df['emails'].str.strip().str.lower()
```
`replace()` es un m√©todo que permite reemplazar partes de un string seg√∫n un patr√≥n. [Documentaci√≥n](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html)

```python
df['fono'] = (df['fono']
              .str.replace(r'\D+', '', regex=True)  # Dejar solo d√≠gitos
              .str.replace(r'^56', '', regex=True))  # Quitar c√≥digo pa√≠s si viene repetido
```

- `.str.replace(r'\D+', '', regex=True)` elimina todo lo que **no es d√≠gito** (`\D`). El signo `+` indica que se eliminar√°n **uno o m√°s** caracteres no num√©ricos consecutivos.
- `.str.replace(r'^56', '', regex=True)` elimina el prefijo `56` si est√° al inicio (`^`), quitando el c√≥digo de pa√≠s chileno.

As√≠, se limpian los n√∫meros de tel√©fono para que queden solo los d√≠gitos relevantes.

**Alternativa con `apply` para reemplazos**

En vez de usar `.str.replace`, puedes aplicar una funci√≥n personalizada con `.apply` y el m√©todo nativo de Python `replace`:

```python
# Ejemplo para limpiar 'fono' usando apply y una funci√≥n definida
def limpiar_fono(x):
    solo_digitos = ''.join([c for c in str(x) if c.isdigit()])
    if solo_digitos.startswith('56'):
        solo_digitos = solo_digitos[2:]
    return solo_digitos

df['fono'] = df['fono'].apply(limpiar_fono)

# Para reemplazar espacios en 'emails' (como en el pipeline)
def limpiar_emails(x):
    return str(x).replace(' ', '') if pd.notnull(x) else x

df['emails'] = df['emails'].apply(limpiar_emails)
```

Esto permite mayor flexibilidad si necesitas l√≥gica m√°s compleja que los patrones regulares.

### Resultado 

|   | id   | nombre_completo | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------------------------|----------------|-----------|--------------|
| 0 | 001  | ana G√ìmez       | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 002  | LUIS  p√©rez     | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 003  | Sof√≠a  D√≠az     | sdiaz@uc.cl;sofia@mail.com | 2024-05-10     | 4500      | 911112222    |
| 3 | 003  | sofia  D√çAZ     | None                       | 10-05-24       | USD 3,000 | 456789123    |

- Se eliminaron espacios extra en todas las columnas con `.str.strip()`.
- En la columna `fono`, se dejaron solo los d√≠gitos relevantes usando `.str.replace(r'\D+', '', regex=True)` y se quit√≥ el prefijo `56` si estaba presente.
- En la columna `emails`, se eliminaron los espacios con `.str.replace(' ', '', regex=True)` y se normaliz√≥ a min√∫sculas.

#### Normalizar ID

```` python
# quitar espacios y ceros a la izquierda ‚Üí Int64 (permite NA)
clean['id'] = (clean['id'].str.strip()
                         .str.replace(r'^0+', '', regex=True)
                         .replace('', None)
                         .astype('Int64'))

clean
````

|   | id   | nombre_completo | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------------------------|----------------|-----------|--------------|
| 0 | 1  | ana G√ìmez       | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 2  | LUIS  p√©rez     | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 3  | Sof√≠a  D√≠az     | sdiaz@uc.cl;sofia@mail.com | 2024-05-10     | 4500      | 911112222    |
| 3 | 3  | sofia  D√çAZ     | None                       | 10-05-24       | USD 3,000 | 456789123    |


### 2.2. Separar columnas con `str.split`
```python
# Columna "nombre_completo" -> "nombre" y "apellido"
df[['nombre', 'apellido']] = df['nombre_completo'].str.strip().str.split(' ', n=1, expand=True)

# - str.split(' ', n=1, expand=True): Divide cada cadena en la columna en dos partes usando el espacio (' ') como separador.
#   - n=1: Limita la divisi√≥n a un m√°ximo de 1 separaci√≥n, obteniendo como resultado dos partes.
#   - expand=True: Devuelve el resultado como un DataFrame, lo que permite asignar directamente las columnas "nombre" y "apellido".


# Columna "region|comuna" separada por '|'
df[['region','comuna']] = df['region_comuna'].str.split('|', expand=True)

# - str.split('|', expand=True): Divide cada cadena en la columna "region_comuna" en dos partes usando el car√°cter '|' como separador.
#   - expand=True: Devuelve el resultado como un DataFrame, lo que permite asignar directamente las columnas "region" y "comuna".

```

|   | id   | nombre_completo | nombre   | apellido | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------|----------|----------------------------|----------------|-----------|--------------|
| 0 | 1  | ana G√ìmez       | Ana      | G√≥mez    | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 2  | LUIS  p√©rez     | Luis     | P√©rez    | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 3  | Sof√≠a  D√≠az     | Sof√≠a    | D√≠az     | sdiaz@uc.cl;sofia@mail.com | 2024-05-10     | 4500      | 911112222    |
| 3 | 3  | sofia  D√çAZ     | Sofia    | D√≠az     | None                       | 10-05-24       | USD 3,000 | 456789123    |

Ahora vamos a normalizar la columna `nombre_completo` usando `.str.strip()`, `.str.title()` y `.str.replace(r'\s+', ' ', regex=True)` para dejar los nombres en formato est√°ndar:

```python
df['nombre_completo'] = (df['nombre_completo'].str.strip().str.title().str.replace(r'\s+', ' ', regex=True))
```

|   | id   | nombre_completo | nombre   | apellido | emails                     | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------|----------|----------------------------|----------------|-----------|--------------|
| 0 | 1  | Ana G√≥mez       | Ana      | G√≥mez    | ana@uc.cl;ana@gmail.com    | 12/03/2024     | 10000     | 123456789    |
| 1 | 2  | Luis P√©rez      | Luis     | P√©rez    | l.perez@uc.cl              | 31-04-2024     | 12.500    | 9876544321   |
| 2 | 3  | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sdiaz@uc.cl;sofia@mail.com | 2024-05-10     | 4500      | 911112222    |
| 3 | 3  | Sofia D√≠az      | Sofia    | D√≠az     | None                       | 10-05-24       | USD 3,000 | 456789123    |

### 2.3. Listas y `explode`
```python
# Columna 'emails' con "correo1;correo2;correo3"
df['emails_list'] = df['emails'].str.split(';') # Transforma emails en una lista con los emails
df = df.drop(columns=['emails'])
df = df.explode('emails_list', ignore_index=True) # despu√©s de "explotar" la columna el √≠ndice del DataFrame se reasigna de forma secuencial empezando desde 0.
df = df.rename(columns={'emails_list':'email'}) # La renombramos
```

|   | id   | nombre_completo | nombre   | apellido | email                   | fecha_atencion | monto     | fono         |
|---|------|-----------------|----------|----------|-------------------------|----------------|-----------|--------------|
| 0 | 1  | Ana G√≥mez       | Ana      | G√≥mez    | ana@uc.cl               | 12/03/2024     | 10000     | 123456789    |
| 1 | 1  | Ana G√≥mez       | Ana      | G√≥mez    | ana@gmail.com           | 12/03/2024     | 10000     | 123456789    |
| 2 | 2  | Luis P√©rez      | Luis     | P√©rez    | l.perez@uc.cl           | 31-04-2024     | 12.500    | 9876544321   |
| 3 | 3  | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sdiaz@uc.cl             | 2024-05-10     | 4500      | 911112222    |
| 4 | 3  | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sofia@mail.com          | 2024-05-10     | 4500      | 911112222    |
| 5 | 3  | Sofia D√≠az      | Sofia    | D√≠az     | None                    | 10-05-24       | USD 3,000 | 456789123    |



### 2.4. Fechas con `to_datetime`
```python
# Convertir strings a fechas, marcando errores como NaT (sin rellenar)
df['fecha_atencion'] = pd.to_datetime(df['fecha_atencion'], format='%d/%m/%Y', errors='coerce') # Si algo no se puede normalizar, queda como `NaT`.
```
Esto solo funciiona si todas las fechas est√°n en el mismo formato

#### Fechas en distinto formato con ``to_datatime``

```python

# Supongamos que tu DF se llama df
col = df['fecha_atencion'].astype(str)

# Lista de formatos que queremos intentar
formatos = ["%d/%m/%Y", "%d-%m-%Y", "%Y-%m-%d", "%d-%m-%y"]

# Lista para guardar los resultados parciales
parsed_list = []

for fmt in formatos:
    parsed = pd.to_datetime(col, format=fmt, errors="coerce")
    parsed_list.append(parsed)

# Concatenar todos los resultados
df_concat = pd.concat(parsed_list, axis=1)

# Tomar el primer valor no nulo por fila
df['fecha_atencion'] = df_concat.bfill(axis=1).iloc[:, 0]

# Normalizar el formato
df['fecha_atencion'] = df['fecha_atencion'].dt.strftime("%Y-%m-%d")
df
```

#### Fechas en distinto formato con `apply`

```python
from datetime import datetime

def parse_fecha(fecha):
    formatos = ["%d/%m/%Y", "%d-%m-%Y", "%Y-%m-%d", "%d-%m-%y"]
    for fmt in formatos:
        try:
            return datetime.strptime(str(fecha), fmt) # Convierte una fecha en un objeto datetime de Python usando el formato especificado en fmt
        except ValueError:
            continue
    return pd.NaT  # si no calza con ninguno

df['fecha_atencion'] = df['fecha_atencion'].apply(parse_fecha)

# Normalizar a YYYY-MM-DD
df['fecha_atencion'] = df['fecha_atencion'].dt.strftime("%Y-%m-%d")

print(df[['nombre_completo','fecha_atencion']])

```
|   | id  | nombre_completo | nombre   | apellido | email                   | fecha_atencion | monto     | fono         |
|---|-----|-----------------|----------|----------|-------------------------|----------------|-----------|--------------|
| 0 | 1   | Ana G√≥mez       | Ana      | G√≥mez    | ana@uc.cl               | 2024-03-12     | 10000     | 123456789    |
| 1 | 1   | Ana G√≥mez       | Ana      | G√≥mez    | ana@gmail.com           | 2024-03-12     | 10000     | 123456789    |
| 2 | 2   | Luis P√©rez      | Luis     | P√©rez    | l.perez@uc.cl           | NaT            | 12.500    | 9876544321   |
| 3 | 3   | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sdiaz@uc.cl             | 2024-05-10     | 4500      | 911112222    |
| 4 | 3   | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sofia@mail.com          | 2024-05-10     | 4500      | 911112222    |
| 5 | 3   | Sofia D√≠az      | Sofia    | D√≠az     | None                    | 2024-05-10     | USD 3,000 | 456789123    |

Puedes encontrar m√°s funciones y utilidades de la librer√≠a datatime en este [link](https://aprendeconalf.es/docencia/python/manual/datetime/)

Tambi√©n est√° la documentaci√≥n de python [link](https://docs.python.org/3/library/datetime.html)

---

## 3. Transformaci√≥n de tipos

### Caso 1: Si es que no tienen comas ni puntos
```python
df['id'] = df['id'].str.replace(r'\D+', '', regex=True)
df['monto'] = df['monto'].str.replace(r'\D+', '', regex=True)

df['id'] = df['id'].astype('Int64') # Entero con soporte de NaN
df['monto'] = pd.to_numeric(df['monto'], errors='coerce')
df['es_titular'] = df['es_titular'].astype('boolean') # boolean con NA
```

> Usa `errors="coerce"` para marcar entradas inv√°lidas como NaN/NaT y **no las rellenes** aqu√≠.

### Caso 3: Con comas y puntos, adem√°s de formatos distintos

```python
def monto_simple(valor):
    if pd.isna(valor):
        return None
    s = str(valor)
    
    # dejar solo d√≠gitos, comas y puntos con replace
    for ch in s:
        if not (ch.isdigit() or ch in [',','.']):
            s = s.replace(ch, '')
    
    # si hay m√°s de un separador -> el √∫ltimo es decimal
    if s.count('.') + s.count(',') > 1:
        # buscamos el √∫ltimo separador
        idx = max(s.rfind('.'), s.rfind(','))
        # quitamos todos los separadores anteriores
        s = s[:idx].replace('.', '').replace(',', '') + '.' + s[idx+1:].replace(',', '').replace('.', '')
    else:
        # si hay solo coma, la usamos como decimal
        s = s.replace(',', '.')
    
    try:
        return float(s)
    except:
        return None

df['monto'] = df['monto'].apply(monto_simple)

```
|   | id  | nombre_completo | nombre   | apellido | email                   | fecha_atencion | monto   | fono         |
|---|-----|-----------------|----------|----------|-------------------------|----------------|---------|--------------|
| 0 | 1   | Ana G√≥mez       | Ana      | G√≥mez    | ana@uc.cl               | 2024-03-12     | 10000   | 123456789    |
| 1 | 1   | Ana G√≥mez       | Ana      | G√≥mez    | ana@gmail.com           | 2024-03-12     | 10000   | 123456789    |
| 2 | 2   | Luis P√©rez      | Luis     | P√©rez    | l.perez@uc.cl           | NaT            | 12500   | 9876544321   |
| 3 | 3   | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sdiaz@uc.cl             | 2024-05-10     | 4500    | 911112222    |
| 4 | 3   | Sof√≠a D√≠az      | Sof√≠a    | D√≠az     | sofia@mail.com          | 2024-05-10     | 4500    | 911112222    |
| 5 | 3   | Sofia D√≠az      | Sofia    | D√≠az     | None                    | 2024-05-10     | 3000    | 456789123    |

## 4. Luego podemos hacer conexi√≥n de DataFrames coo ya sabemos

### 4.1. `concat`
```python
# Apilar por filas (mismas columnas)
df_all = pd.concat([df_2023, df_2024], axis=0, ignore_index=True)

# Unir por columnas (mismo √≠ndice o reindexar)
df_cols = pd.concat([dfA.set_index('id'), dfB.set_index('id')], axis=1).reset_index()
```

### 4.2. `merge`
```python
# En clave com√∫n
df_ab = pd.merge(a, b, on='id', how='inner')      # inner/left/right/outer
# Nombres distintos
df_ab = pd.merge(a, b, left_on='id_afiliado', right_on='id_paciente', how='left')
# Varias claves
df_ab = pd.merge(a, b, on=['id','fecha'], how='outer')
```

### 4.3. `join`
```python
df_join = a.set_index('id').join(b.set_index('id'), how='left').reset_index()
```

> Consejo: al unir, **verifica duplicados** en las claves y el **cardinal** (1‚Äë1, 1‚ÄëN, N‚Äë1, N‚ÄëN).

### 4.4. Cardinalidad

#### Cardinalidad en uni√≥n de DataFrames

La **cardinalidad** describe la relaci√≥n entre las filas de los DataFrames que vas a unir. Es clave para evitar duplicados inesperados y entender el resultado de la uni√≥n.

- **1 a 1 (uno a uno):** Cada valor de la clave aparece una sola vez en ambos DataFrames.
    - Ejemplo:
        ```python
        df1 = pd.DataFrame({'id': [1,2], 'nombre': ['Ana','Luis']})
        df2 = pd.DataFrame({'id': [1,2], 'edad': [23, 34]})
        pd.merge(df1, df2, on='id')
        ```
        | id | nombre | edad |
        |----|--------|------|
        | 1  | Ana    | 23   |
        | 2  | Luis   | 34   |

- **1 a N (uno a muchos):** La clave aparece una vez en el primer DataFrame y varias veces en el segundo.
    - Ejemplo:
        ```python
        df1 = pd.DataFrame({'id': [1,2], 'nombre': ['Ana','Luis']})
        df2 = pd.DataFrame({'id': [1,1,2], 'email': ['ana@a.com','ana@b.com','luis@c.com']})
        pd.merge(df1, df2, on='id')
        ```
        | id | nombre | email      |
        |----|--------|------------|
        | 1  | Ana    | ana@a.com  |
        | 1  | Ana    | ana@b.com  |
        | 2  | Luis   | luis@c.com |

- **N a 1 (muchos a uno):** La clave aparece varias veces en el primer DataFrame y una vez en el segundo.
    - Ejemplo:
        ```python
        df1 = pd.DataFrame({'id': [1,1,2], 'email': ['ana@a.com','ana@b.com','luis@c.com']})
        df2 = pd.DataFrame({'id': [1,2], 'nombre': ['Ana','Luis']})
        pd.merge(df1, df2, on='id')
        ```
        | id | email      | nombre |
        |----|------------|--------|
        | 1  | ana@a.com  | Ana    |
        | 1  | ana@b.com  | Ana    |
        | 2  | luis@c.com | Luis   |

- **N a N (muchos a muchos):** La clave aparece varias veces en ambos DataFrames. El resultado puede tener muchas combinaciones.
    - Ejemplo:
        ```python
        df1 = pd.DataFrame({'id': [1,1], 'fecha': ['2024-01-01','2024-01-02']})
        df2 = pd.DataFrame({'id': [1,1], 'valor': [10,20]})
        pd.merge(df1, df2, on='id')
        ```
        | id | fecha       | valor |
        |----|-------------|-------|
        | 1  | 2024-01-01  | 10    |
        | 1  | 2024-01-01  | 20    |
        | 1  | 2024-01-02  | 10    |
        | 1  | 2024-01-02  | 20    |


**Ejemplo de mal uso de `merge`**

Un error com√∫n es unir DataFrames sin revisar duplicados en la clave, lo que genera combinaciones inesperadas (N a N):

```python
df1 = pd.DataFrame({'id': [1,1,2], 'nombre': ['Ana','Ana','Luis']})
df2 = pd.DataFrame({'id': [1,1,2], 'email': ['ana@a.com','ana@b.com','luis@c.com']})

# Mal uso: no se revis√≥ duplicados en 'id'
df_merged = pd.merge(df1, df2, on='id')
print(df_merged)
```

Resultado:

| id | nombre | email      |
|----|--------|------------|
| 1  | Ana    | ana@a.com  |
| 1  | Ana    | ana@b.com  |
| 1  | Ana    | ana@a.com  |
| 1  | Ana    | ana@b.com  |
| 2  | Luis   | luis@c.com |

Aqu√≠, para cada combinaci√≥n de `id=1`, se cruzan todas las filas, generando duplicados inesperados.  
**Soluci√≥n:** Revisa duplicados antes de unir y aseg√∫rate de la cardinalidad adecuada.

**Recomendaci√≥n:**  
Antes de unir, revisa con `value_counts()` o `duplicated()` cu√°ntas veces aparece cada clave. As√≠ evitas duplicados inesperados y entiendes la estructura del resultado.

---

## 5. Checklist limpieza y transformaci√≥n para I1 / Tarea 2

- [ ] Report√© `df.info()` y `isna().sum()` inicial.  
- [ ] Document√© las **reglas de limpieza** (qu√© elimin√© y por qu√©).  
- [ ] Normalic√© strings (`strip`, `lower/title`, `replace`, `split`).  
- [ ] Convert√≠ tipos con `astype`/`to_datetime` (`errors='coerce'`).  
- [ ] Desanid√© listas con `explode`.  
- [ ] Revis√© duplicados y cardinalidad antes de `merge`. 